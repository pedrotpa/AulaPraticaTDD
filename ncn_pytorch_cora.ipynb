{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ncn_pytorch_cora.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOl0wc/rLZNimGMjOUOEsAe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrotpa/AulaPraticaTDD/blob/master/ncn_pytorch_cora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m3PjJaFIrIG",
        "colab_type": "code",
        "outputId": "da29495c-0e37-4cc8-e811-ae70bc56976d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tkipf/pygcn/master/data/cora/cora.cites -P data/cora\n",
        "!wget https://raw.githubusercontent.com/tkipf/pygcn/master/data/cora/cora.content -P data/cora"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-22 17:27:04--  https://raw.githubusercontent.com/tkipf/pygcn/master/data/cora/cora.cites\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69928 (68K) [text/plain]\n",
            "Saving to: ‘data/cora/cora.cites’\n",
            "\n",
            "\rcora.cites            0%[                    ]       0  --.-KB/s               \rcora.cites          100%[===================>]  68.29K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-03-22 17:27:04 (3.00 MB/s) - ‘data/cora/cora.cites’ saved [69928/69928]\n",
            "\n",
            "--2020-03-22 17:27:07--  https://raw.githubusercontent.com/tkipf/pygcn/master/data/cora/cora.content\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7823427 (7.5M) [text/plain]\n",
            "Saving to: ‘data/cora/cora.content’\n",
            "\n",
            "cora.content        100%[===================>]   7.46M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-22 17:27:08 (71.5 MB/s) - ‘data/cora/cora.content’ saved [7823427/7823427]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnXUHvZlvtrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_cora(path=\"data/cora/\"):\n",
        "    path=\"data/cora/\"\n",
        "    content = pd.read_csv(path+\"cora.content\", sep='\\t', header=None, index_col=False)\n",
        "    node_idx = content[0].to_numpy().astype(np.int32)\n",
        "    idx_map = {j:i for i,j in enumerate(node_idx)}\n",
        "\n",
        "    del node_idx\n",
        "\n",
        "    node_features= content.iloc[:,1:-1].to_numpy().astype(np.int8)\n",
        "\n",
        "    label_column = content.columns[-1]\n",
        "    # content[label_column] = pd.Categorical(content[label_column])\n",
        "    # node_labels = pd.get_dummies(content[label_column]).to_numpy().astype(np.int8)\n",
        "    node_labels = pd.Categorical(content[label_column]).codes\n",
        "    del content\n",
        "\n",
        "    cites = np.genfromtxt(path+\"cora.cites\",delimiter='\\t', dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, cites.flatten())),\n",
        "                        dtype=np.int32).reshape(cites.shape)\n",
        "\n",
        "    adj = np.zeros((len(idx_map),len(idx_map), 2), dtype=np.float32)\n",
        "    adj[edges[:,0], edges[:,1],0]=1\n",
        "    adj[edges[:,1], edges[:,0],1]=1\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    return adj, node_features, node_labels, idx_train, idx_val, idx_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwDS_PzBGTIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3zpE8yFRsRL",
        "colab_type": "code",
        "outputId": "f531b550-3002-456e-8a40-952745d28f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar 20 23:32:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hAixfk_1O6Xm",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NodeConv(nn.Module):\n",
        "    def __init__(self,in_size, out_size, edges_size = 1,bias=True, device='cpu'):\n",
        "        super(NodeConv, self).__init__()\n",
        "        self.in_size = in_size;\n",
        "        self.out_size = out_size\n",
        "        self.edges_size = edges_size\n",
        "        self.kernel = nn.parameter.Parameter(torch.FloatTensor(out_size, edges_size*in_size).to(device))\n",
        "        var = 2./(self.kernel.size(1)+self.kernel.size(0))\n",
        "        self.kernel.data.normal_(0,var)\n",
        "        if bias:\n",
        "            self.bias=nn.parameter.Parameter(torch.FloatTensor(out_size).to(device))\n",
        "            self.bias.data.normal_(0,var)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "    def forward(self, X, adj):\n",
        "        X = X.T@adj\n",
        "        X = X.view(X.shape[0], -1)\n",
        "        X = X@self.kernel.T\n",
        "        if self.bias is not None:\n",
        "            return X + self.bias\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_size) + ' -> ' \\\n",
        "               + str(self.out_size) + ')'\n",
        "\n",
        "class NCN(nn.Module):\n",
        "    def __init__(self, in_size, n_hid, out_size, edges_size, dropout, bias=True, device='cpu'):\n",
        "        super(NCN, self).__init__()\n",
        "        self.ncn1 = NodeConv(in_size, n_hid, edges_size=edges_size, bias=bias, device=device)\n",
        "        self.ncn2 = NodeConv(n_hid, out_size, edges_size=edges_size, bias=bias, device=device)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, X, adj):\n",
        "        X = F.relu(self.ncn1(X,adj))\n",
        "        X = F.dropout(X, self.dropout, training=self.training)\n",
        "        return F.log_softmax(self.ncn2(X, adj), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqpxS5hwSJiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NodeConv(nn.Module):\n",
        "    def __init__(self,in_size, out_size, edges_size = 1,bias=True, device='cpu'):\n",
        "        super(NodeConv, self).__init__()\n",
        "        self.in_size = in_size;\n",
        "        self.out_size = out_size\n",
        "        self.edges_size = edges_size\n",
        "        self.kernel = nn.parameter.Parameter(torch.FloatTensor(out_size, edges_size*in_size).to(device))\n",
        "        var = 2./(self.kernel.size(1)+self.kernel.size(0))\n",
        "        self.kernel.data.normal_(0,var)\n",
        "        if bias:\n",
        "            self.bias=nn.parameter.Parameter(torch.FloatTensor(out_size).to(device))\n",
        "            self.bias.data.normal_(0,var)\n",
        "        else:\n",
        "            self.register_parameter(\"bias\", None)\n",
        "\n",
        "    def forward(self, X, adj):\n",
        "        X = X.T@adj\n",
        "        X = X.view(X.shape[0], -1)\n",
        "        X = X@self.kernel.T\n",
        "        if self.bias is not None:\n",
        "            return X + self.bias\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_size) + ' -> ' \\\n",
        "               + str(self.out_size) + ')'\n",
        "\n",
        "class NCN(nn.Module):\n",
        "    def __init__(self, in_size, n_hid, out_size, edges_size, dropout, bias=True, device='cpu'):\n",
        "        super(NCN, self).__init__()\n",
        "        self.ncn1 = NodeConv(in_size, n_hid, edges_size=edges_size, bias=bias, device=device)\n",
        "        self.ncn2 = NodeConv(n_hid, out_size, edges_size=edges_size, bias=bias, device=device)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, X, adj):\n",
        "        X = F.relu(self.ncn1(X,adj))\n",
        "        X = F.dropout(X, self.dropout, training=self.training)\n",
        "        return F.log_softmax(self.ncn2(X, adj), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK2Yy-p49iSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj, node_features, node_labels, idx_train, idx_val, idx_test = load_cora()\n",
        "\n",
        "\n",
        "use_GPU = False\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() and use_GPU else 'cpu')\n",
        "\n",
        "adj = torch.from_numpy(np.copy(adj)).to(device).float()\n",
        "node_features = torch.from_numpy(np.copy(node_features)).to(device).float()\n",
        "# node_labels = torch.from_numpy(np.copy(node_labels)).to(device).float()\n",
        "node_labels = torch.LongTensor(node_labels).to(device)\n",
        "\n",
        "idx_train = torch.LongTensor(idx_train).to(device)\n",
        "idx_val = torch.LongTensor(idx_val).to(device)\n",
        "idx_test = torch.LongTensor(idx_test).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSqQNqy0Mnn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NCN(in_size=node_features.shape[1], n_hid=128, out_size=7, dropout = 0.5,\n",
        "            edges_size = adj.shape[-1], bias = True, device=device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQGXEL3P-B8H",
        "colab_type": "code",
        "outputId": "f81dbe77-e8f0-44f7-ce2f-1f3b0d2b0580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(100):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(node_features, adj)\n",
        "    loss_train = F.nll_loss(output[idx_train], node_labels[idx_train])\n",
        "    acc_train = accuracy(output[idx_train], node_labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate validation set performance separately,\n",
        "    # deactivates dropout during validation run.\n",
        "    model.eval()\n",
        "    output = model(node_features, adj)\n",
        "\n",
        "    loss_val = F.nll_loss(output[idx_val], node_labels[idx_val])\n",
        "    acc_val = accuracy(output[idx_val], node_labels[idx_val])\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.6f}'.format(loss_train.item()),\n",
        "          'acc_train: {:.6f}'.format(acc_train.item()),\n",
        "          'loss_val: {:.6f}'.format(loss_val.item()),\n",
        "          'acc_val: {:.6f}'.format(acc_val.item()),\n",
        "          'time: {:.6f}s'.format(time.time() - t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 1.946966 acc_train: 0.135714 loss_val: 2.117717 acc_val: 0.376667 time: 1.980345s\n",
            "Epoch: 0002 loss_train: 1.773531 acc_train: 0.357143 loss_val: 3.091569 acc_val: 0.293333 time: 1.770749s\n",
            "Epoch: 0003 loss_train: 2.546145 acc_train: 0.464286 loss_val: 2.014833 acc_val: 0.503333 time: 1.743530s\n",
            "Epoch: 0004 loss_train: 1.127110 acc_train: 0.685714 loss_val: 1.377938 acc_val: 0.663333 time: 1.726611s\n",
            "Epoch: 0005 loss_train: 0.751519 acc_train: 0.800000 loss_val: 1.215742 acc_val: 0.726667 time: 1.723158s\n",
            "Epoch: 0006 loss_train: 0.593705 acc_train: 0.892857 loss_val: 1.252734 acc_val: 0.703333 time: 1.726669s\n",
            "Epoch: 0007 loss_train: 0.555923 acc_train: 0.892857 loss_val: 1.265209 acc_val: 0.710000 time: 1.709360s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-88252deffd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# deactivates dropout during validation run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e8580b8aa84e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, adj)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-e8580b8aa84e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, adj)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLmxSMiJAm7g",
        "colab_type": "code",
        "outputId": "e2bdaa0b-e096-41e8-8d6a-3690b46b11b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "node_labels[idx_train]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZTAfK61_uJw",
        "colab_type": "code",
        "outputId": "8b6b1e1c-69cc-4cd6-90a1-cc8f8ac7fa07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "#a=adj f=features\n",
        "a=np.stack([[[1,0,1],[1,0,0],[-1,-1,-1]], [[0,-1,0],[0,0,1],[0,1,0]]], axis=2)\n",
        "# a = np.array([[[1,0],[0,-1],[0,0]]]) #2 tipos de arestas, 1 no\n",
        "f=np.array([[1,2,3,4,5],[10,20,30,40,50],[5,10,15,20,25]]) #5 features por no, 3 nos\n",
        "\n",
        "n_out=3\n",
        "w = np.ones((n_out,a.shape[-1]*f.shape[-1]))\n",
        "w[0,-n_out:]=0\n",
        "w[1,:-n_out]=0\n",
        "# w =np.eye(f.shape[-1])\n",
        "# w = np.array([[[1,1,1,1,1],[0,0,0,0,0]],[[0,0,0,0,0],[1,1,1,1,1]],[[1,0,1,0,1],[0,1,0,1,0]]])\n",
        "# tem que transformar de 5 canais para n\n",
        "\n",
        "print(f\"a: {a}\")\n",
        "print(a.shape)\n",
        "print(f\"f: {f}\")\n",
        "print(f\"w: {w}\")\n",
        "# print(w.shape)\n",
        "# print(\"\\n\")\n",
        "\n",
        "# tmp=f.T@a\n",
        "tmp = f.T@a\n",
        "print(tmp)\n",
        "# print(tmp.shape)\n",
        "\n",
        "tmp = tmp.reshape(tmp.shape[0],-1)\n",
        "print(f\"tmp: {tmp}\")\n",
        "print(f\"tmp reshaped: {tmp.shape}\")\n",
        "# print(f\"w: {w.shape}\")\n",
        "res = tmp@w.T\n",
        "print(f\"res: {res}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a: [[[ 1  0]\n",
            "  [ 0 -1]\n",
            "  [ 1  0]]\n",
            "\n",
            " [[ 1  0]\n",
            "  [ 0  0]\n",
            "  [ 0  1]]\n",
            "\n",
            " [[-1  0]\n",
            "  [-1  1]\n",
            "  [-1  0]]]\n",
            "(3, 3, 2)\n",
            "f: [[ 1  2  3  4  5]\n",
            " [10 20 30 40 50]\n",
            " [ 5 10 15 20 25]]\n",
            "w: [[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
            "[[[  6 -10]\n",
            "  [ 12 -20]\n",
            "  [ 18 -30]\n",
            "  [ 24 -40]\n",
            "  [ 30 -50]]\n",
            "\n",
            " [[  1   5]\n",
            "  [  2  10]\n",
            "  [  3  15]\n",
            "  [  4  20]\n",
            "  [  5  25]]\n",
            "\n",
            " [[-16  10]\n",
            "  [-32  20]\n",
            "  [-48  30]\n",
            "  [-64  40]\n",
            "  [-80  50]]]\n",
            "tmp: [[  6 -10  12 -20  18 -30  24 -40  30 -50]\n",
            " [  1   5   2  10   3  15   4  20   5  25]\n",
            " [-16  10 -32  20 -48  30 -64  40 -80  50]]\n",
            "tmp reshaped: (3, 10)\n",
            "res: [[   0.  -60.  -60.]\n",
            " [  40.   50.   90.]\n",
            " [-100.   10.  -90.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGyrlzMsQE_Y",
        "colab_type": "code",
        "outputId": "b75e4a8c-ea84-4ec7-8070-da84215f1424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "device='cpu'\n",
        "adj = torch.from_numpy(np.copy(a)).to(device).float()\n",
        "feat = torch.from_numpy(np.copy(f)).to(device).float()\n",
        "weights = torch.from_numpy(np.copy(w)).to(device).float()\n",
        "\n",
        "# adj = adj.to_sparse()\n",
        "\n",
        "print(adj)\n",
        "print(feat)\n",
        "print(weights,'\\n\\n')\n",
        "\n",
        "tmp = feat.T@adj\n",
        "print(f\"tmp_shape before view: {tmp.shape}\")\n",
        "print(tmp)\n",
        "tmp = tmp.view(tmp.shape[0], -1)\n",
        "print(tmp,'\\n\\n')\n",
        "out = torch.matmul(tmp,weights.T)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0b13c5deb5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT86iNPDXRy9",
        "colab_type": "code",
        "outputId": "4e3b1abc-b3f5-4549-c142-268a90276e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "device='cpu'\n",
        "# a=np.stack([[[1,0,1],[1,0,0],[-1,-1,-1]], [[0,-1,0],[0,0,1],[0,1,0]]], axis=0)\n",
        "a=np.stack([[[1,0,1],[1,0,0]], [[0,-1,0],[0,0,1]]], axis=0)\n",
        "n_out=4\n",
        "w = np.ones((n_out,a.shape[0]*f.shape[-1]))\n",
        "w[0,-n_out:]=0\n",
        "w[1,:-n_out]=0\n",
        "\n",
        "adj = torch.from_numpy(np.copy(a)).to(device).float()\n",
        "feat = torch.from_numpy(np.copy(f)).to(device).float()\n",
        "weights = torch.from_numpy(np.copy(w)).to(device).float()\n",
        "\n",
        "print(adj)\n",
        "print(feat)\n",
        "tmp=adj@feat\n",
        "print(tmp)\n",
        "tmp=tmp.permute(1,0,2).reshape(-1,2,5)\n",
        "print(tmp)\n",
        "print(weights)\n",
        "# tmp@weights.T"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  0.,  1.],\n",
            "         [ 1.,  0.,  0.]],\n",
            "\n",
            "        [[ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  1.]]])\n",
            "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
            "        [10., 20., 30., 40., 50.],\n",
            "        [ 5., 10., 15., 20., 25.]])\n",
            "tensor([[[  6.,  12.,  18.,  24.,  30.],\n",
            "         [  1.,   2.,   3.,   4.,   5.]],\n",
            "\n",
            "        [[-10., -20., -30., -40., -50.],\n",
            "         [  5.,  10.,  15.,  20.,  25.]]])\n",
            "tensor([[[  6.,  12.,  18.,  24.,  30.],\n",
            "         [-10., -20., -30., -40., -50.]],\n",
            "\n",
            "        [[  1.,   2.,   3.,   4.,   5.],\n",
            "         [  5.,  10.,  15.,  20.,  25.]]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DvP1ye8wy_I",
        "colab_type": "code",
        "outputId": "c3c60f7a-7a23-41f0-9a94-45563c79a145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "device='cpu'\n",
        "a=np.stack([[[1,0,1],[1,0,0],[-1,-1,-1]], [[0,-1,0],[0,0,1],[0,1,0]]], axis=0)\n",
        "# a=np.stack([[[1,0,1],[1,0,0]], [[0,-1,0],[0,0,1]]], axis=0)\n",
        "n_out=3\n",
        "w = np.ones((n_out,a.shape[0]*f.shape[-1]))\n",
        "w[0,-n_out:]=0\n",
        "w[1,:-n_out]=0\n",
        "\n",
        "adj = torch.from_numpy(np.copy(a)).to(device).float()\n",
        "feat = torch.from_numpy(np.copy(f)).to(device).float()\n",
        "weights = torch.from_numpy(np.copy(w)).to(device).float()\n",
        "\n",
        "print(adj)\n",
        "print(feat)\n",
        "tmp=adj@feat\n",
        "print(tmp)\n",
        "# print(tmp.)\n",
        "# a@f\n",
        "print(weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  0.,  1.],\n",
            "         [ 1.,  0.,  0.],\n",
            "         [-1., -1., -1.]],\n",
            "\n",
            "        [[ 0., -1.,  0.],\n",
            "         [ 0.,  0.,  1.],\n",
            "         [ 0.,  1.,  0.]]])\n",
            "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
            "        [10., 20., 30., 40., 50.],\n",
            "        [ 5., 10., 15., 20., 25.]])\n",
            "tensor([[[  6.,  12.,  18.,  24.,  30.],\n",
            "         [  1.,   2.,   3.,   4.,   5.],\n",
            "         [-16., -32., -48., -64., -80.]],\n",
            "\n",
            "        [[-10., -20., -30., -40., -50.],\n",
            "         [  5.,  10.,  15.,  20.,  25.],\n",
            "         [ 10.,  20.,  30.,  40.,  50.]]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P46NslXBTpXU",
        "colab_type": "code",
        "outputId": "999bd73f-c76d-4eb9-c788-9a090a504491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "device='cpu'\n",
        "adj = torch.from_numpy(np.copy(a)).to(device).float()\n",
        "feat = torch.from_numpy(np.copy(f)).to(device).float()\n",
        "weights = torch.from_numpy(np.copy(w)).to(device).float()\n",
        "\n",
        "print(f\"adj_shape:{adj.shape}\\nadj_t_shape:{adj.T.shape}\")\n",
        "print(f\"feat_shape:{feat.shape}\\nfeat_t_shape:{feat.T.shape}\")\n",
        "adj = adj.T.to_sparse()\n",
        "print(adj[0])\n",
        "# print(adj[0]@feat)\n",
        "# print(f.T@a)\n",
        "\n",
        "# adj_s = adj.to_sparse()\n",
        "# feat_s = feat.to_sparse()\n",
        "\n",
        "# adjt_s = adj.T.to_sparse()\n",
        "# featt_s = feat.T.to_sparse()\n",
        "\n",
        "# torch.sparse.mm(adj_s, feat.T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adj_shape:torch.Size([2, 3, 2])\n",
            "adj_t_shape:torch.Size([2, 3, 2])\n",
            "feat_shape:torch.Size([3, 5])\n",
            "feat_t_shape:torch.Size([5, 3])\n",
            "tensor(indices=tensor([[0, 0, 2],\n",
            "                       [0, 1, 0]]),\n",
            "       values=tensor([1., 1., 1.]),\n",
            "       size=(3, 2), nnz=3, layout=torch.sparse_coo)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJqJfZA0VzcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERagXPAsVtJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lPCEYEPQsKh",
        "colab_type": "code",
        "outputId": "d92ee9a5-1d7f-42ab-c21e-a8b6db0ec72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "i = torch.LongTensor([[0, 1, 1],\n",
        "                          [2, 0, 2]])\n",
        "v = torch.FloatTensor([3, 4, 5])\n",
        "torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 3.],\n",
              "        [4., 0., 5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e14W8dczROPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = torch.randn((3,4,5)).to_sparse()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbQn3YhkShMI",
        "colab_type": "code",
        "outputId": "bad932a7-d592-48ff-8f21-9e3f3cdb312c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "t1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "                        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "                        1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "                        2, 2, 2],\n",
              "                       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
              "                        3, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3,\n",
              "                        3, 3, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
              "                        3, 3, 3],\n",
              "                       [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3,\n",
              "                        4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2,\n",
              "                        3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1,\n",
              "                        2, 3, 4]]),\n",
              "       values=tensor([-0.7561, -1.0995,  0.7820, -2.8600,  1.5064,  2.0398,\n",
              "                      -0.2025,  1.4670, -0.8606,  0.3663, -0.8735,  0.0400,\n",
              "                      -0.1551,  0.0811, -0.4835,  1.5184, -2.2704, -0.8166,\n",
              "                      -0.4117, -1.3348,  0.3080, -1.4410, -2.3757, -0.5975,\n",
              "                       0.3580, -1.2116, -1.2121, -0.3463, -0.1286, -0.2271,\n",
              "                      -0.9113, -0.5895, -0.6911, -0.8040, -2.8766,  0.8216,\n",
              "                       1.7507, -0.8813,  1.3618,  1.4729,  1.6041,  0.2922,\n",
              "                       0.0575, -1.3415, -1.1787,  1.0651,  0.9496,  0.9121,\n",
              "                      -2.2220, -0.6694,  1.3163,  0.1269,  0.5641, -0.1620,\n",
              "                       1.1649,  0.2827,  1.0188,  0.9584,  0.6863, -2.0280]),\n",
              "       size=(3, 4, 5), nnz=60, layout=torch.sparse_coo)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO2ekuf2SqNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}